No, it was not a “Sputnik moment”. The launch last month of DeepSeek R1, the Chinese generative AI or chatbot, created mayhem in the tech world, with stocks plummeting and much chatter about the US losing its supremacy in AI technology. Yet, for all the disruption, the Sputnik analogy reveals less about DeepSeek than about American neuroses.

The original Sputnik moment came on 4 October 1957 when the Soviet Union shocked the world by launching Sputnik 1, the first time humanity had sent a satellite into orbit. It was, to anachronistically borrow a phrase from a later and even more momentous landmark, “one giant leap for mankind”, in Neil Armstrong’s historic words as he took a “small step” on to the surface of the moon.

It was a significant moment in the cold war, too. A confidential White House report worried that “American prestige” had “sustained a severe blow”, giving the USSR “clear advantage in the cold war”. That fear spurred Washington into reshaping its space programme, and catalysed the Apollo missions, culminating with Armstrong and Buzz Aldrin becoming, on 20 July 1969, the first humans to walk upon another celestial body.

DeepSeek, sponsored by a Chinese hedge fund, is a notable achievement. Technically, though, it is no advance on large language models (LLMs) that already exist. It is neither faster nor “cleverer” than OpenAI’s ChatGPT or Anthropic’s Claude and just as prone to “hallucinations” – the tendency, exhibited by all LLMs, to give false answers or to make up “facts” to fill gaps in its data. According to NewsGuard, a rating system for news and information websites, DeepSeek’s chatbot made false claims 30% of the time and gave no answers to 53% of questions, compared with 40% and 22% respectively for the 10 leading chatbots in NewsGuard’s most recent audit.

The figures expose the profound unreliability of all LLMs. DeepSeek’s particularly high non-response rate is likely to be the product of its censoriousness; it refuses to provide answers on any issue that China finds sensitive or about which it wants facts restricted, whether Tiananmen Square or Taiwan.

The true impact of DeepSeek is not on the technology but on the economics of AI. It is a chatbot as capable, and as flawed, as other current leading models, but built at a fraction of the cost and from inferior technology. The US ban on the sale to China of the most advanced chips and chip-making equipment, imposed by the Biden administration in 2022, and tightened several times since, was designed to curtail Beijing’s access to cutting-edge technology. Paradoxically, it may have spurred Chinese researchers into becoming more innovative.

Had DeepSeek been created by geeks at a US university, it would most likely have been feted without global tumult

DeepSeek is also free to use, and open source. The combination of low cost and openness may help democratise AI technology, enabling others, especially from outside America, to enter the market. There is a certain irony that it should be China that is opening up the technology while US firms continue to create as many barriers as possible to competitors attempting to enter the field.

And here lies perhaps the biggest impact of DeepSeek. It has ripped off the veil of mystique that previously surrounded AI. Silicon Valley has nurtured the image of AI technology as a precious and miraculous accomplishment, and portrayed its leading figures, from Elon Musk to Sam Altman, as prophets guiding us into a new world. The technology itself has been endowed with almost magical powers, including the promise of “artificial general intelligence”, or AGI – superintelligent machines capable of surpassing human abilities on any cognitive task – as being almost within our grasp.

Last April, Musk predicted that AI would be “smarter than any human” by the end of 2025. Last month, Altman, the CEO of OpenAI, the driving force behind the current generative AI boom, similarly claimed to be “confident we know how to build AGI” and that “in 2025, we may see the first AI agents ‘join the workforce’”.

Almost a decade ago, the Nobel prize-winning computer scientist Geoff Hinton urged nations to “stop training radiologists”, and similar medical technicians, because “it’s completely obvious within five years, deep learning [AI] is going to do better”. Dario Amodei, the CEO of Anthropic, a corporation founded by former OpenAI employees, has claimed that AI could double the human lifespan within five to 10 years. These fantasy claims have been shredded by critics such as the American cognitive scientist Gary Marcus, who has even challenged Musk to a $1m bet over his “smarter than any human” claim for AI.

Nevertheless, for all the pushback, each time one fantasy prediction fails to materialise, another takes its place. Such claims derive less from technological possibilities than from political and economic needs. While AI technology has provided hugely important tools, capable of surpassing humans in specific fields, from the solving of mathematical problems to the recognition of disease patterns, the business model depends on hype. It is the hype that drives the billion-dollar investment and buys political influence, including a seat at the presidential inauguration.

It is also an approach that seeks to advance AI less through major scientific breakthroughs than through a brute force strategy of “scaling up” – building bigger models, using larger datasets, and deploying vastly greater computational power. The disruptive quality of DeepSeek lies in questioning this approach, demonstrating that the best generative AI models can be matched with much less computational power and a lower financial burden.

The hype around DeepSeek is in part a reflection of the hype around AI. It is a reflection, too, of geopolitical tensions. Had DeepSeek been created by geeks at a US university, it would most likely have been feted but without the global tumult of the past two weeks. Beneath the panic lies fear of DeepSeek’s Chinese origins and ownership.

Yet, too great an obsession with the geopolitics of DeepSeek can distort the lessons we take from it. The promise of more open access to such vital technology becomes subsumed into a fear of its Chinese provenance. Concerns about privacy, censorship and surveillance, rightly raised by a model such as DeepSeek, can help obscure the reality that such issues bedevil all AI technology, not just that from China. Particularly at a time of threatened trade wars and threats to democracy, our capacity to navigate between the hype and the fear assumes new importance.