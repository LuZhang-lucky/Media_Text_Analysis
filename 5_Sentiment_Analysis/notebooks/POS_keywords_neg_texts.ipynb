{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74443e2f-a021-4697-8855-bbd4ff2520e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "pd.options.display.max_rows = 400\n",
    "pd.options.display.max_colwidth =  400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c1f054d-763e-417d-826b-785a98e49ac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“„ Global_AI_rivalry_is_a_dangerous_game.txt â€” 85 adjectives found:\n",
      "former, senior, senior, chief, incoming, human, artificial, general, existential, numerous, last, least, different, intelligent, possible, chinese, focused, widespread, chinese, less, american, chinese, human, top, chinese, chinese, official, precise, general, many, human, chinese, obvious, physical, necessary, slow, practical, industrial, vast, future, chinese, abstract, imminent, tangible, wrong, human, third, possible, worrying, secretive, new, large, nuclear, cold, strong, different, direct, intense, profound, technological, unexpected, technological, right, human, irretrievable, strategic, multiple, offensive, diplomatic, military, ugly, own, key, strategic, unprecedented, ill, prepared, strategic, technological, many, alone, geopolitical, new, dangerous, many\n",
      "\n",
      "ðŸ“„ What_questions_will_China's_DeepSeek_not_answer?_â€“.txt â€” 162 adjectives found:\n",
      "sensitive, advanced, low, other, chinese, artificial, regulatory, sensitive, clear, nuanced, controversial, vague, lgbtq+, cheap, sovereign, inseparable, official, sovereign, english, detailed, international, legal, independent, own, democratic, sovereign, diplomatic, diplomatic, political, potential, political, analytical, official, inseparable, national, english, comprehensive, multidimensional, political, touchy, political, surprising, chinese, inseparable, english, detailed, cultural, local, chinese, single, taiwanese, excellent, traditional, chinese, english, thorough, chinese, dedicated, socialist, separatist, english, detailed, english, factual, chinese, political, high, high, great, chinese, nonstarter, weekslong, peaceful, political, oppressive, social, sensitive, public, iconic, protester, dual, international, human, chinese, vocational, widespread, ethnic, english, detailed, mass, cultural, widespread, international, dissident, chinese, specific, chinese, english, clear, detailed, persistent, social, human, absolute, chinese, constitutional, political, small, questionable, chinese, spiritual, chinese, inseparable, religious, english, historical, long, distinct, cultural, political, global, previous, sensitive, many, many, touchy, controversial, chinese, pandemic, chinese, entire, english, official, low, independent, true, high, different, chinese, same, legal, different, social, legal, cultural, political, chinese, strict, non, -, political, chinese, ideological, english, balanced, many, non, -, political, english, neutral, informative\n",
      "\n",
      "ðŸ“„ DeepSeek:_Is_China's_AI_tool_as_good_as_it_seems?.txt â€” 25 adjectives found:\n",
      "good, chinese, last, other, chatty, good, long, subjective, good, soft, tasty, well, rival, artificial, same, similar, current, such, dissimilar, early, similar, real, fast, many, viral\n",
      "\n",
      "ðŸ“„ First_Thing:_Donald_Trump_calls_Chinaâ€™s_DeepSeek_A.txt â€” 14 adjectives found:\n",
      "good, chinese, american, artificial, chinese, comparable, few, single, large, absolute, chinese, focused, impressive, sensitive\n",
      "\n",
      "ðŸ“„ South_Korea_Bans_Downloads_of_DeepSeek,_the_Chines.txt â€” 16 adjectives found:\n",
      "south, korean, new, artificial, chinese, available, accessible, personal, chinese, last, top, american, few, expensive, last, such\n",
      "\n",
      "ðŸ“„ DeepSeekâ€™s_tech_breakthrough_hailed_in_China_as_an.txt â€” 19 adjectives found:\n",
      "positive, chinese, various, disruptive, chief, chinese, recent, powerful, new, low, less, large, social, chief, national, open, complex, hard, previous\n",
      "\n",
      "ðŸ“„ DeepSeek_has_ripped_away_AIâ€™s_veil_of_mystique._Th.txt â€” 116 adjectives found:\n",
      "last, chinese, generative, much, less, american, original, first, momentous, giant, historic, small, significant, cold, confidential, american, severe, clear, cold, first, celestial, chinese, notable, large, prone, false, false, recent, profound, high, non, -, response, likely, sensitive, true, capable, other, current, leading, inferior, advanced, several, chinese, innovative, global, free, open, low, certain, many, possible, big, precious, miraculous, new, magical, artificial, general, capable, human, cognitive, last, smart, last, current, generative, confident, first, similar, medical, obvious, deep, former, human, such, american, cognitive, smart, human, such, technological, political, economic, important, capable, specific, mathematical, political, presidential, major, scientific, brute, big, large, great, computational, disruptive, good, generative, less, computational, low, financial, geopolitical, global, past, chinese, great, open, such, vital, chinese, such, such, new\n",
      "\n",
      "ðŸ“„ DeepSeek:_South_Korea_temporarily_bans_AI_app_â€“_DW.txt â€” 34 adjectives found:\n",
      "chinese, many, sensitive, ChineseAI, available, local, personal, local, domestic, lacking, local, south, korean, able, extreme, compliant, local, chinese, recent, western, such, many, wary, personal, secure, many, south, korean, much, sensitive, private, economic, technological, cheap\n",
      "\n",
      "ðŸ“„ South_Korea_removes_DeepSeek_from_app_stores_pendi.txt â€” 25 adjectives found:\n",
      "artificial, chinese, local, personal, available, further, necessary, local, significant, last, personal, temporary, similar, italian, further, last, tiny, such, less, existential, huge, last, single, advanced, more\n",
      "\n",
      "ðŸ“„ US_tech_stocks_plunge_on_China_AIâ€™s_unexpectedly_s.txt â€” 10 adjectives found:\n",
      "loud, major, artificial, chinese, high, chinese, many, american, much, heavy\n",
      "\n",
      "ðŸ“„ Diving_into_DeepSeek:_inside_the_7_February_Guardi.txt â€” 37 adjectives found:\n",
      "first, big, cheap, less, intensive, such, stealth, tricky, such, contentious, chinese, typical, real, new, more, technical, illegal, own, significant, essential, arduous, northern, hot, intent, nordic, local, mean, inside, environmental, well, ultimate, old, wise, new, wide, artificial, sweet\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import spacy\n",
    "\n",
    "# Load spaCy English model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Folder containing the .txt files\n",
    "folder_path = \"../negative_DeepSeek_texts\"  # adjust if necessary\n",
    "\n",
    "# Store adjectives per file\n",
    "adjectives_by_file = {}\n",
    "\n",
    "# Loop through each .txt file in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".txt\"):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        \n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            text = file.read()\n",
    "            doc = nlp(text)\n",
    "\n",
    "            # Extract all adjectives (in lemma form)\n",
    "            adjectives = [token.lemma_ for token in doc if token.pos_ == \"ADJ\"]\n",
    "            adjectives_by_file[filename] = adjectives\n",
    "\n",
    "# Display adjectives per file\n",
    "for file, adjectives in adjectives_by_file.items():\n",
    "    print(f\"\\nðŸ“„ {file} â€” {len(adjectives)} adjectives found:\")\n",
    "    print(\", \".join(adjectives))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f701849-c702-4739-bd52-c2798c0dedf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”¤ Top 50 Adjectives:\n",
      "chinese: 44\n",
      "political: 13\n",
      "many: 12\n",
      "english: 12\n",
      "such: 11\n",
      "human: 10\n",
      "last: 10\n",
      "artificial: 9\n",
      "new: 8\n",
      "sensitive: 8\n",
      "local: 8\n",
      "american: 7\n",
      "less: 6\n",
      "large: 5\n",
      "technological: 5\n",
      "low: 5\n",
      "detailed: 5\n",
      "high: 5\n",
      "good: 5\n",
      "personal: 5\n",
      "different: 4\n",
      "official: 4\n",
      "inseparable: 4\n",
      "cultural: 4\n",
      "social: 4\n",
      "similar: 4\n",
      "first: 4\n",
      "chief: 3\n",
      "general: 3\n",
      "possible: 3\n",
      "widespread: 3\n",
      "cold: 3\n",
      "strategic: 3\n",
      "diplomatic: 3\n",
      "own: 3\n",
      "advanced: 3\n",
      "other: 3\n",
      "clear: 3\n",
      "cheap: 3\n",
      "sovereign: 3\n",
      "international: 3\n",
      "legal: 3\n",
      "single: 3\n",
      "great: 3\n",
      "global: 3\n",
      "non: 3\n",
      "-: 3\n",
      "current: 3\n",
      "south: 3\n",
      "korean: 3\n",
      "\n",
      "ðŸ”§ Top 20 Verbs:\n",
      "say: 27\n",
      "use: 16\n",
      "ask: 13\n",
      "take: 12\n",
      "make: 9\n",
      "lead: 7\n",
      "create: 7\n",
      "build: 7\n",
      "see: 7\n",
      "send: 7\n",
      "provide: 7\n",
      "give: 7\n",
      "remain: 6\n",
      "let: 6\n",
      "come: 6\n",
      "consider: 6\n",
      "claim: 6\n",
      "have: 6\n",
      "suspend: 6\n",
      "appear: 5\n"
     ]
    }
   ],
   "source": [
    "# Create counters for adjectives and verbs\n",
    "adjective_counter = Counter()\n",
    "verb_counter = Counter()\n",
    "\n",
    "# Loop through each file\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".txt\"):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        \n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            text = file.read()\n",
    "            doc = nlp(text)\n",
    "\n",
    "            # Extract adjectives and verbs\n",
    "            for token in doc:\n",
    "                if token.pos_ == \"ADJ\":\n",
    "                    adjective_counter[token.lemma_.lower()] += 1\n",
    "                elif token.pos_ == \"VERB\":\n",
    "                    verb_counter[token.lemma_.lower()] += 1\n",
    "\n",
    "# Show top 50 most common adjectives and verbs\n",
    "print(\"ðŸ”¤ Top 50 Adjectives:\")\n",
    "for word, freq in adjective_counter.most_common(50):\n",
    "    print(f\"{word}: {freq}\")\n",
    "\n",
    "print(\"\\nðŸ”§ Top 20 Verbs:\")\n",
    "for word, freq in verb_counter.most_common(20):\n",
    "    print(f\"{word}: {freq}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7cffb7ac-32dd-4dcd-b63f-56fafca60c0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adj</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chinese</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>political</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>many</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>english</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>such</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>human</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>last</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>artificial</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>new</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>sensitive</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>local</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>american</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>less</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>large</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>technological</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>low</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>detailed</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>high</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>good</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>personal</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>different</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>official</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>inseparable</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>cultural</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>social</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>similar</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>first</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>chief</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>general</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>possible</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>widespread</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>cold</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>strategic</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>diplomatic</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>own</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>advanced</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>other</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>clear</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>cheap</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>sovereign</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>international</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>legal</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>single</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>great</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>global</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>non</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>-</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>current</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>south</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>korean</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>available</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>recent</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>open</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>generative</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>much</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>significant</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>capable</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>big</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>former</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>senior</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>existential</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>focused</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>top</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>obvious</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>necessary</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>profound</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>geopolitical</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>controversial</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>independent</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>national</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>touchy</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>specific</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>absolute</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>small</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>long</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>previous</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>true</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>same</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>well</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>real</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>few</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>disruptive</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>false</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>cognitive</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>smart</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>economic</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>major</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>computational</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>further</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>more</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>incoming</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>numerous</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>least</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>intelligent</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>precise</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>physical</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>slow</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>practical</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>industrial</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>vast</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              adj  count\n",
       "0         chinese     44\n",
       "1       political     13\n",
       "2            many     12\n",
       "3         english     12\n",
       "4            such     11\n",
       "5           human     10\n",
       "6            last     10\n",
       "7      artificial      9\n",
       "8             new      8\n",
       "9       sensitive      8\n",
       "10          local      8\n",
       "11       american      7\n",
       "12           less      6\n",
       "13          large      5\n",
       "14  technological      5\n",
       "15            low      5\n",
       "16       detailed      5\n",
       "17           high      5\n",
       "18           good      5\n",
       "19       personal      5\n",
       "20      different      4\n",
       "21       official      4\n",
       "22    inseparable      4\n",
       "23       cultural      4\n",
       "24         social      4\n",
       "25        similar      4\n",
       "26          first      4\n",
       "27          chief      3\n",
       "28        general      3\n",
       "29       possible      3\n",
       "30     widespread      3\n",
       "31           cold      3\n",
       "32      strategic      3\n",
       "33     diplomatic      3\n",
       "34            own      3\n",
       "35       advanced      3\n",
       "36          other      3\n",
       "37          clear      3\n",
       "38          cheap      3\n",
       "39      sovereign      3\n",
       "40  international      3\n",
       "41          legal      3\n",
       "42         single      3\n",
       "43          great      3\n",
       "44         global      3\n",
       "45            non      3\n",
       "46              -      3\n",
       "47        current      3\n",
       "48          south      3\n",
       "49         korean      3\n",
       "50      available      3\n",
       "51         recent      3\n",
       "52           open      3\n",
       "53     generative      3\n",
       "54           much      3\n",
       "55    significant      3\n",
       "56        capable      3\n",
       "57            big      3\n",
       "58         former      2\n",
       "59         senior      2\n",
       "60    existential      2\n",
       "61        focused      2\n",
       "62            top      2\n",
       "63        obvious      2\n",
       "64      necessary      2\n",
       "65       profound      2\n",
       "66   geopolitical      2\n",
       "67  controversial      2\n",
       "68    independent      2\n",
       "69       national      2\n",
       "70         touchy      2\n",
       "71       specific      2\n",
       "72       absolute      2\n",
       "73          small      2\n",
       "74           long      2\n",
       "75       previous      2\n",
       "76           true      2\n",
       "77           same      2\n",
       "78           well      2\n",
       "79           real      2\n",
       "80            few      2\n",
       "81     disruptive      2\n",
       "82          false      2\n",
       "83      cognitive      2\n",
       "84          smart      2\n",
       "85       economic      2\n",
       "86          major      2\n",
       "87  computational      2\n",
       "88        further      2\n",
       "89           more      2\n",
       "90       incoming      1\n",
       "91       numerous      1\n",
       "92          least      1\n",
       "93    intelligent      1\n",
       "94        precise      1\n",
       "95       physical      1\n",
       "96           slow      1\n",
       "97      practical      1\n",
       "98     industrial      1\n",
       "99           vast      1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(adjective_counter.most_common(), columns=['adj', 'count'])\n",
    "df[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e4bdfb43-46b3-43bb-a41d-e55a2d8e7305",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save top 20 adjectives to CSV\n",
    "df.head(20).to_csv(\"../outputs/top_adjectives_negative_texts.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1bb56c-1fb0-40f2-be39-0fe29355534f",
   "metadata": {},
   "source": [
    "Keyword Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6335a307-3540-4d9b-bb89-2c876fd95a79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## ðŸ“„ Global_AI_rivalry_is_a_dangerous_game.txt"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Many struggle to stay up to date with AI developments, let alone plan for the geo**political** ramifications of new breakthroughs."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## ðŸ“„ What_questions_will_China's_DeepSeek_not_answer?_â€“.txt"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "The DeepSeek AI chatbot becomes tongue-tied when asked about issues seen as **political**ly sensitive by China's Communist Party."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "However, like other Chinese artificial intelligence chatbots operating under China's regulatory framework, DeepSeek's responses to **political**ly sensitive topics reveal clear limitations.  "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\"  We then tested four more **political**ly related questions, covering Taiwan's elections, diplomatic ties, **political** parties and potential conflict scenarios.  "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Only the question about Taiwan's **political** parties received a response."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "However, one response covering Taiwan's **political** parties was also deleted within two seconds of being generated.  "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Beijing considers Taiwan as its territory that will eventually be \"reunited\" with the mainland, so the responses to **political** questions were not surprising."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "However, the Chinese version inserted **political** slogans, even calling Taiwan's highest mountain, Yushan, \"the highest peak in Eastern China\" and concluding with \"the great rejuvenation of the Chinese nation will inevitably be achieved."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "The student-led protesters were calling for **political** reforms.  "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "To this day, it remains one of the most **political**ly sensitive topics in China, and any mention of the massacre in the public sphere is censored.  "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "When asked, \"what impact will Xi Jinping's constitutional amendment to remove term limits have on China's **political** system?\""
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\"Tibet has a long history as a distinct cultural and **political** entity â€¦"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\"The LGBTQ+ community in China faces social stigma, legal limitations, cultural barriers, and lack of representation.\"  DeepSeek's self-censorship  In summary, when it comes to **political** questions, DeepSeek's Chinese version mostly refused to answer or followed strict government narratives."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Even on non-**political** questions, the Chinese version still injected ideological messaging into answers.  "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "However, on non-**political** topics, the English responses mostly remained neutral and informative.  "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## ðŸ“„ DeepSeek:_Is_China's_AI_tool_as_good_as_it_seems?.txt"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "_No sentences with keyword found._"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## ðŸ“„ First_Thing:_Donald_Trump_calls_Chinaâ€™s_DeepSeek_A.txt"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "_No sentences with keyword found._"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## ðŸ“„ South_Korea_Bans_Downloads_of_DeepSeek,_the_Chines.txt"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "_No sentences with keyword found._"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## ðŸ“„ DeepSeek_has_ripped_away_AIâ€™s_veil_of_mystique._Th.txt"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Such claims derive less from technological possibilities than from **political** and economic needs."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "It is the hype that drives the billion-dollar investment and buys **political** influence, including a seat at the presidential inauguration.  "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "It is a reflection, too, of geo**political** tensions."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## ðŸ“„ Diving_into_DeepSeek:_inside_the_7_February_Guardi.txt"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "_No sentences with keyword found._"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import spacy\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "# Load spaCy English model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def find_sentences_with_keyword(doc, keyword):\n",
    "    \"\"\"\n",
    "    Find and display sentences from a spaCy document that contain a specific keyword.\n",
    "    Keyword will be highlighted using Markdown (bolded).\n",
    "    \"\"\"\n",
    "    found = False  # to track if any sentence matched\n",
    "\n",
    "    for sentence in doc.sents:\n",
    "        sentence_text = sentence.text\n",
    "\n",
    "        if keyword.lower() in sentence_text.lower():\n",
    "            sentence_clean = re.sub(r\"\\n\", \" \", sentence_text)\n",
    "            sentence_highlighted = re.sub(\n",
    "                f\"({re.escape(keyword)})\", r\"**\\1**\", sentence_clean, flags=re.IGNORECASE\n",
    "            )\n",
    "            display(Markdown(sentence_highlighted))\n",
    "            found = True\n",
    "    \n",
    "    if not found:\n",
    "        display(Markdown(\"_No sentences with keyword found._\"))\n",
    "\n",
    "# Folder with your .txt files\n",
    "folder_path = \"../negative_DeepSeek_texts\"\n",
    "\n",
    "# Keyword to search\n",
    "keyword = \"political\"\n",
    "\n",
    "# Loop through files and process each\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".txt\"):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        \n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            text = file.read()\n",
    "            doc = nlp(text)\n",
    "\n",
    "            # Display the filename\n",
    "            display(Markdown(f\"## ðŸ“„ {filename}\"))\n",
    "            # Find and display matching sentences\n",
    "            find_sentences_with_keyword(doc, keyword=keyword)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7cfb80-8f5c-4a57-8c93-907e0f5ca772",
   "metadata": {},
   "source": [
    "When I used part-of-speech tagging to analyze the texts with negative sentiment scores, I found that the most frequent adjective was \"Chinese\", followed by \"political\". The word political appeared 13 times across 11 articles, making it a notable and valuable term for further analysis.\n",
    "\n",
    "Because of its frequency and prominence, I selected political as a keyword and examined all the sentences in which it appeared. I also included geopolitical in this keyword search. By zooming in on these sentences, we can see the specific contexts and topics being discussed in the articles â€” particularly how they relate to political or geopolitical concerns involving China and the United States.\n",
    "\n",
    "This method helps explain why these articles were assigned highly negative sentiment scores. The negativity may not stem from the AI tool DeepSeek itself, but rather from underlying political anxieties, such as fears of censorship, state control, or geopolitical competition.\n",
    "\n",
    "This demonstrates that POS-based adjective analysis is a valuable research tool. It helps identify dominant themes in highly negative articles â€” in this case, clearly pointing toward politics as a central topic. For example, several articles mention that DeepSeek is owned by the Chinese government, which raises concerns about state influence over the technology. Others highlight that DeepSeek avoids answering sensitive political questions, reinforcing concerns about censorship and control.\n",
    "\n",
    "Therefore, we can confidently conclude that the political dimension â€” both domestic and international â€” is a major theme in these negative articles."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (numpy_env)",
   "language": "python",
   "name": "numpy_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
