{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35e0c70d-573a-4b17-84ae-9b8eba24a3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the files\n",
    "import glob\n",
    "directory_path = \"negative_DeepSeek_texts\"\n",
    "text_files = glob.glob(f\"{directory_path}/*.txt\")\n",
    "\n",
    "texts = []\n",
    "\n",
    "for filepath in text_files:\n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        texts.append(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3a82a5-8f16-4991-8939-164d84c34c23",
   "metadata": {},
   "source": [
    "2️⃣ Preprocess the Texts\n",
    "We need to lowercase, remove punctuation/numbers, tokenize, remove stopwords, and lemmatize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14cce628-767e-4470-9d67-856374048bdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/lulu/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /Users/lulu/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/lulu/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example tokens from first doc: ['julian', 'gewirtz', 'publishedjul', 'print', 'page', 'writer', 'former', 'senior', 'director', 'china', 'taiwan', 'affair', 'white', 'house', 'national', 'security', 'council', 'senior', 'research', 'scholar', 'columbia', 'school', 'international', 'public', 'affair', 'phone', 'call', 'donald', 'trump', 'day', 'inauguration', 'sam', 'altman', 'chief', 'executive', 'openai', 'told', 'incoming', 'president', 'u', 'would', 'achieve', 'humanlevel', 'artificial', 'general', 'intelligence', 'term', 'office', 'altman', 'framed']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "custom_stopwords = {'deepseek','ai','chinese','say'}  # noise words\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "texts_tokens = []\n",
    "\n",
    "for text in texts:\n",
    "    text = text.lower()                          # lowercase\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)         # keep only letters\n",
    "    tokens = nltk.word_tokenize(text)            # tokenize\n",
    "    tokens = [t for t in tokens if t not in stop_words and t not in custom_stopwords]\n",
    "    tokens = [lemmatizer.lemmatize(t) for t in tokens]  # lemmatize\n",
    "    \n",
    "    if tokens:\n",
    "        texts_tokens.append(tokens)\n",
    "\n",
    "print(\"Example tokens from first doc:\", texts_tokens[0][:50])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ecb750-5b11-46ac-944b-f399184c9fca",
   "metadata": {},
   "source": [
    "Now we have texts_tokens = list of lists, where each inner list is a document’s cleaned tokens."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77748532-b56b-427e-876f-26e588b5143e",
   "metadata": {},
   "source": [
    "3️⃣ Create Dictionary and Corpus for LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88477812-2b73-474b-9a61-f42ca2f36059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique tokens: 379\n",
      "Number of documents: 11\n"
     ]
    }
   ],
   "source": [
    "from gensim import corpora\n",
    "\n",
    "dictionary = corpora.Dictionary(texts_tokens)\n",
    "dictionary.filter_extremes(no_below=2, no_above=0.5)  # optional filtering\n",
    "\n",
    "corpus = [dictionary.doc2bow(text) for text in texts_tokens]\n",
    "\n",
    "print(\"Number of unique tokens:\", len(dictionary))\n",
    "print(\"Number of documents:\", len(corpus))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e848af7-6b4c-444f-9a27-c62a9bb63b7f",
   "metadata": {},
   "source": [
    "4️⃣ Train LDA Topic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a9a6eb0-2291-459b-9b64-c2cdf74c118c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1: 0.021*\"version\" + 0.020*\"taiwan\" + 0.014*\"response\" + 0.012*\"technology\" + 0.012*\"however\" + 0.011*\"answer\" + 0.010*\"word\" + 0.010*\"political\" + 0.009*\"app\" + 0.008*\"video\"\n",
      "Topic 2: 0.021*\"app\" + 0.012*\"chatgpt\" + 0.011*\"trump\" + 0.011*\"monday\" + 0.011*\"company\" + 0.010*\"month\" + 0.009*\"south\" + 0.009*\"last\" + 0.009*\"data\" + 0.008*\"rival\"\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import LdaModel\n",
    "\n",
    "num_topics = 2  # adjust based on your corpus size\n",
    "\n",
    "lda_model = LdaModel(\n",
    "    corpus=corpus,\n",
    "    id2word=dictionary,\n",
    "    num_topics=num_topics,\n",
    "    random_state=42,\n",
    "    passes=10,\n",
    "    alpha='auto',\n",
    "    per_word_topics=True\n",
    ")\n",
    "\n",
    "# Print topics\n",
    "for idx, topic in lda_model.print_topics(num_words=10):\n",
    "    print(f\"Topic {idx+1}: {topic}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5567a974-2113-4964-b6ea-4afa024c61a5",
   "metadata": {},
   "source": [
    "5️⃣ (Optional) Visualize Topics\n",
    "If you want interactive topic visualization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d7e43a9-f819-4040-945e-57e387aba1b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el472350205229768055951742\" style=\"background-color:white;\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el472350205229768055951742_data = {\"mdsDat\": {\"x\": [0.06848258675674004, -0.06848258675674004], \"y\": [0.0, 0.0], \"topics\": [1, 2], \"cluster\": [1, 1], \"Freq\": [59.80872066898684, 40.19127933101316]}, \"tinfo\": {\"Term\": [\"chatgpt\", \"app\", \"trump\", \"monday\", \"rival\", \"taiwan\", \"google\", \"company\", \"word\", \"political\", \"korea\", \"south\", \"version\", \"month\", \"guardian\", \"downloads\", \"stock\", \"seems\", \"donald\", \"video\", \"look\", \"whether\", \"far\", \"industry\", \"chip\", \"human\", \"last\", \"good\", \"dollar\", \"week\", \"word\", \"political\", \"video\", \"human\", \"beijing\", \"provided\", \"issue\", \"let\", \"party\", \"right\", \"war\", \"support\", \"authority\", \"taiwan\", \"social\", \"claimed\", \"javascript\", \"consider\", \"upgrading\", \"html\", \"please\", \"enable\", \"llm\", \"xi\", \"executive\", \"international\", \"may\", \"could\", \"jinping\", \"version\", \"answer\", \"response\", \"however\", \"official\", \"two\", \"technology\", \"asked\", \"sensitive\", \"part\", \"claim\", \"also\", \"one\", \"use\", \"data\", \"agi\", \"even\", \"app\", \"topic\", \"rival\", \"google\", \"guardian\", \"downloads\", \"seems\", \"good\", \"dollar\", \"value\", \"service\", \"look\", \"far\", \"real\", \"share\", \"try\", \"nvidia\", \"nothing\", \"opinion\", \"subject\", \"investor\", \"censor\", \"monday\", \"saw\", \"assistant\", \"offer\", \"questioned\", \"fewer\", \"chart\", \"via\", \"billion\", \"korea\", \"chatgpt\", \"trump\", \"stock\", \"company\", \"whether\", \"south\", \"donald\", \"chip\", \"month\", \"app\", \"export\", \"industry\", \"mean\", \"apple\", \"control\", \"week\", \"last\", \"home\", \"personal\", \"information\", \"data\", \"day\", \"new\", \"agi\", \"store\", \"technology\"], \"Freq\": [8.0, 20.0, 8.0, 7.0, 5.0, 20.0, 4.0, 8.0, 9.0, 9.0, 5.0, 7.0, 21.0, 8.0, 3.0, 3.0, 5.0, 3.0, 6.0, 8.0, 3.0, 5.0, 3.0, 6.0, 5.0, 8.0, 8.0, 3.0, 3.0, 6.0, 9.253376241547059, 9.246062416398033, 7.632736730847828, 7.5476067718684074, 6.774118202533479, 5.227544167953054, 5.211270438270785, 5.190074236663466, 5.188922023705941, 5.184908879610536, 5.153129704255768, 4.414612758307332, 4.39032296717648, 18.192585257437234, 3.620787885940635, 3.6112488921288133, 3.6103007879015596, 3.609283227050017, 3.6079528983320457, 3.6067486994348688, 3.6053310172937123, 3.605267100154796, 3.6018402892803807, 5.7612467384161485, 3.5676113830480927, 3.5584060367014128, 4.977443221202959, 3.551679610059024, 3.545503723039832, 19.00442666680731, 10.035544758346777, 13.146028860038681, 10.539643892863804, 4.868966035834567, 6.037833669190249, 10.877484322318129, 7.591283483460996, 5.938491521315729, 5.902993646818829, 6.0110084982157295, 5.094117992694456, 6.357592366159502, 4.878472644962671, 7.504102210436632, 6.577767734583392, 5.4997259295130645, 7.884149257288479, 5.236810874753093, 5.0976571480993895, 4.3425144249776135, 3.5655485867129832, 3.5393140020916882, 3.5169428178470716, 2.778291419546943, 2.7666883327797196, 2.7654621928143373, 2.7546265173285764, 3.435990090772512, 3.374942523332136, 1.9845187015232881, 1.9841447316973213, 1.9840837396812947, 1.9840800171638846, 1.9840568230169449, 1.983906204235583, 1.9837683279176637, 2.644298832676079, 1.9826505704784134, 6.608478636849991, 1.982282470776055, 1.9822329326597516, 1.9802935010890992, 1.9794118371578961, 1.9776195881986884, 1.9775293887383671, 1.9774987495566072, 1.9753920910499942, 4.608650652956505, 7.1608051531383605, 7.06949695532394, 4.4345751440038566, 6.525962452463197, 4.291079829227534, 5.790994914661584, 4.735095692604682, 4.169709439851776, 6.15735018809215, 12.892140713006036, 2.5379476556600267, 4.573382663970914, 2.5325691906974455, 3.0500443536026602, 2.513675983103817, 4.430322311036585, 5.600183826475689, 3.324406772362844, 3.997741162100727, 3.9367995432327922, 5.3174025050713665, 3.2987254110981863, 3.6412668816139826, 3.846227544823089, 3.3485301169176367, 3.5799564471749563], \"Total\": [8.0, 20.0, 8.0, 7.0, 5.0, 20.0, 4.0, 8.0, 9.0, 9.0, 5.0, 7.0, 21.0, 8.0, 3.0, 3.0, 5.0, 3.0, 6.0, 8.0, 3.0, 5.0, 3.0, 6.0, 5.0, 8.0, 8.0, 3.0, 3.0, 6.0, 9.665600947199634, 9.665500609129175, 8.053575413374205, 8.052406655611986, 7.246897134689284, 5.6358994241381595, 5.635672357414215, 5.635377733130136, 5.635361532264546, 5.635306319011972, 5.634870811836963, 4.829849589033085, 4.8295070745422155, 20.121913915838654, 4.024068885581123, 4.023935583668041, 4.023919791084829, 4.023905341294994, 4.02388684202971, 4.0238706988813355, 4.023850607267044, 4.0238499729241, 4.023806214506715, 6.438105135164533, 4.023325937461718, 4.0231998826651, 5.632457885788986, 4.023107161014659, 4.023022099933966, 21.722898949659204, 12.061078586215581, 16.078294480871325, 12.862913396789454, 5.630968929021883, 7.2368021925406385, 14.457440769493084, 9.642862620258168, 7.235444649042393, 7.234966786602073, 8.031394227680138, 6.428971645084371, 8.831079192261601, 6.426028078689702, 12.821504715507999, 10.423995279406482, 8.024419705108244, 20.776289970294513, 7.225874770034091, 5.57107200785128, 4.775582522913731, 3.9803775828415886, 3.980734978166335, 3.9810192770747714, 3.1853140290747506, 3.18547084363955, 3.1854871729582706, 3.185635231680962, 3.982107659977235, 3.9829495667492987, 2.3903395356787693, 2.3903442482687387, 2.390345362406025, 2.3903451553312554, 2.390345637157856, 2.390347727074221, 2.390349642865539, 3.1871189166841263, 2.3903645503921624, 7.967990109464776, 2.3903694071953785, 2.3903701239295483, 2.3903959313234324, 2.390407802362134, 2.3904320784909183, 2.390433466964235, 2.3904335346412964, 2.390460590024546, 5.577801835298219, 8.766280855272598, 8.76753053367959, 5.580152969867027, 8.77506105289708, 5.582130186992233, 7.979279766330983, 6.381955718144287, 5.583825750356745, 8.780151207111949, 20.776289970294513, 3.1885544601433264, 6.384207834571785, 3.1886288195659502, 3.9874390511739217, 3.1888897675198398, 6.386171847866619, 8.787847873408644, 4.789559320363754, 6.39216240874538, 6.393002244125116, 12.821504715507999, 4.789916949264949, 7.203024093908761, 10.423995279406482, 6.401128513978798, 14.457440769493084], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -4.594, -4.5948, -4.7866, -4.7978, -4.9059, -5.1651, -5.1682, -5.1723, -5.1725, -5.1733, -5.1794, -5.3341, -5.3396, -3.918, -5.5323, -5.535, -5.5352, -5.5355, -5.5359, -5.5362, -5.5366, -5.5366, -5.5376, -5.0679, -5.5471, -5.5497, -5.2141, -5.5516, -5.5533, -3.8743, -4.5129, -4.2429, -4.4639, -5.2361, -5.021, -4.4323, -4.792, -5.0375, -5.0435, -5.0254, -5.1909, -4.9694, -5.2342, -4.8036, -4.9353, -5.1143, -4.7541, -5.1633, -4.7927, -4.953, -5.1502, -5.1576, -5.1639, -5.3997, -5.4039, -5.4043, -5.4082, -5.1872, -5.2051, -5.7361, -5.7363, -5.7363, -5.7363, -5.7364, -5.7364, -5.7365, -5.4491, -5.7371, -4.5331, -5.7373, -5.7373, -5.7383, -5.7387, -5.7396, -5.7397, -5.7397, -5.7407, -4.8936, -4.4529, -4.4657, -4.9321, -4.5457, -4.965, -4.6652, -4.8665, -4.9937, -4.6039, -3.8649, -5.4901, -4.9012, -5.4923, -5.3063, -5.4998, -4.933, -4.6987, -5.2202, -5.0358, -5.0511, -4.7505, -5.228, -5.1292, -5.0744, -5.213, -5.1462], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.4704, 0.4697, 0.4603, 0.4493, 0.4466, 0.4388, 0.4357, 0.4317, 0.4315, 0.4307, 0.4246, 0.4241, 0.4187, 0.4132, 0.4084, 0.4058, 0.4056, 0.4053, 0.4049, 0.4046, 0.4042, 0.4042, 0.4032, 0.4029, 0.3938, 0.3913, 0.3904, 0.3894, 0.3877, 0.3803, 0.3302, 0.3127, 0.3148, 0.3686, 0.3329, 0.2295, 0.2748, 0.3165, 0.3106, 0.2243, 0.2813, 0.1854, 0.2385, -0.0217, 0.0536, 0.1362, -0.4549, 0.1921, 0.8227, 0.8165, 0.8015, 0.794, 0.7876, 0.7748, 0.7706, 0.7701, 0.7662, 0.764, 0.7459, 0.7255, 0.7253, 0.7252, 0.7252, 0.7252, 0.7251, 0.7251, 0.7248, 0.7245, 0.7244, 0.7243, 0.7243, 0.7233, 0.7229, 0.7219, 0.7219, 0.7219, 0.7208, 0.7207, 0.7092, 0.6963, 0.6817, 0.6154, 0.6485, 0.591, 0.613, 0.6195, 0.5567, 0.4343, 0.6833, 0.5779, 0.6812, 0.6435, 0.6736, 0.5459, 0.4609, 0.5464, 0.4422, 0.4267, 0.0314, 0.5385, 0.2294, -0.0855, 0.2636, -0.4843]}, \"token.table\": {\"Topic\": [1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 2, 1, 1, 2, 2, 2, 1, 2, 1, 2, 1, 2, 1, 1, 2, 1, 1, 2, 1, 1, 2, 1, 2, 2, 1, 2, 2, 1, 1, 2, 1, 1, 2, 1, 2, 2, 2, 2, 2, 1, 2, 1, 2, 1, 1, 2, 1, 2, 1, 2, 1, 1, 2, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 2, 2, 2, 1, 2, 1, 2, 2, 1, 2, 1, 1, 2, 1, 1, 1, 2, 2, 1, 2, 1, 2, 2, 2, 1, 2, 2, 2, 1, 1, 2, 1, 2, 1, 2, 2, 1, 1, 2, 1, 2, 1, 2, 1, 2, 2, 1, 2, 1, 1, 2, 2, 1, 2, 2, 1, 1, 1, 2, 1, 2, 1, 1, 2], \"Freq\": [0.6715275489263809, 0.383730027957932, 0.7777293595349778, 0.15554587190699556, 0.8291132446005985, 0.1658226489201197, 0.38505431005430835, 0.625713253838251, 0.25078753233998524, 0.7523625970199558, 0.8296291583780561, 0.20740728959451402, 0.8366905108034836, 0.8282418760881837, 0.9659306417490815, 0.8366588465612241, 0.8366924616882728, 0.836668339713269, 0.22814692262535408, 0.7985142291887393, 0.17908868304783884, 0.7163547321913554, 0.747068295977932, 0.24902276532597734, 0.9940516981024278, 0.22791864215459806, 0.7977152475410932, 0.9940591690739672, 0.31358876377145845, 0.9407662913143753, 0.9942563893801847, 0.6239517262216312, 0.3899698288885195, 0.20877188698510898, 0.626315660955327, 0.9417760033779996, 0.3133835595746738, 0.7834588989366844, 1.0048395640351167, 0.9940728473763727, 0.6230980162736333, 0.37385880976417996, 0.9942023246875111, 0.3136217406664742, 0.9408652219994226, 0.25107021398118134, 0.753210641943544, 0.8366688256888695, 0.9418223674704439, 0.8375941533430933, 1.004929787878165, 0.20878747565528696, 0.6263624269658609, 0.8551717375898347, 0.15548577047087903, 0.9940677271543612, 0.9934918021588662, 0.12418647526985828, 0.3132730092478495, 0.7831825231196238, 0.31284206130819225, 0.6256841226163845, 0.9942334750095161, 0.31376300230441306, 0.9412890069132392, 0.8872055866452326, 0.9940555994337102, 0.9942774115174898, 0.17928209526406286, 0.8964104763203143, 0.3413805112714537, 0.6827610225429074, 0.8872519708138146, 0.9940836578011912, 0.25112329584924303, 0.753369887547729, 0.8877119192697892, 0.17754238385395785, 0.3136144269486106, 0.9408432808458317, 0.12550216381570933, 0.8785151467099652, 0.34167976487352414, 0.6833595297470483, 0.5553223129411161, 0.5553223129411161, 0.836699081885923, 0.8366992505410119, 0.8366814776549208, 0.8879466505720031, 0.17758933011440062, 0.6794186610009808, 0.22647288700032692, 0.8366983503475431, 0.8293058112044106, 0.1382176352007351, 0.8872545215374623, 0.3128831641173131, 0.6257663282346262, 0.9940726906650137, 0.9311468038706032, 0.8871698417089121, 0.8366773225989541, 0.8367012176084319, 0.8085434693005757, 0.18658695445397902, 0.8872632146244431, 0.8974933357446339, 0.8366907616787989, 1.0047678048269024, 0.8292510399888272, 0.13820850666480455, 0.9417274049976501, 0.8366995680427811, 0.9940187689958874, 0.25064918871990327, 0.7519475661597097, 0.17920655677362723, 0.7168262270945089, 0.46866735973955115, 0.46866735973955115, 0.8366976797596899, 0.8281831403368366, 0.894547112928039, 0.09939412365867101, 0.7608538866167314, 0.2766741405879023, 0.691957743405012, 0.27678309736200485, 0.2281144037442699, 0.7984004131049446, 0.8366991780580529, 0.8290954817287286, 0.13818258028812144, 0.9940637391240205, 0.7780856135038121, 0.31123424540152483, 0.9417711756829917, 0.8746530582327309, 0.1381031144577996, 0.8366683160258275, 0.9933476238038034, 0.8873317893103576, 0.31317666477580386, 0.6263533295516077, 0.1791430809568454, 0.7165723238273816, 0.9311371376869769, 0.9319512300643197, 0.15532520501071995], \"Term\": [\"agi\", \"agi\", \"also\", \"also\", \"answer\", \"answer\", \"app\", \"app\", \"apple\", \"apple\", \"asked\", \"asked\", \"assistant\", \"authority\", \"beijing\", \"billion\", \"censor\", \"chart\", \"chatgpt\", \"chatgpt\", \"chip\", \"chip\", \"claim\", \"claim\", \"claimed\", \"company\", \"company\", \"consider\", \"control\", \"control\", \"could\", \"data\", \"data\", \"day\", \"day\", \"dollar\", \"donald\", \"donald\", \"downloads\", \"enable\", \"even\", \"even\", \"executive\", \"export\", \"export\", \"far\", \"far\", \"fewer\", \"good\", \"google\", \"guardian\", \"home\", \"home\", \"however\", \"however\", \"html\", \"human\", \"human\", \"industry\", \"industry\", \"information\", \"information\", \"international\", \"investor\", \"investor\", \"issue\", \"javascript\", \"jinping\", \"korea\", \"korea\", \"last\", \"last\", \"let\", \"llm\", \"look\", \"look\", \"may\", \"may\", \"mean\", \"mean\", \"monday\", \"monday\", \"month\", \"month\", \"new\", \"new\", \"nothing\", \"nvidia\", \"offer\", \"official\", \"official\", \"one\", \"one\", \"opinion\", \"part\", \"part\", \"party\", \"personal\", \"personal\", \"please\", \"political\", \"provided\", \"questioned\", \"real\", \"response\", \"response\", \"right\", \"rival\", \"saw\", \"seems\", \"sensitive\", \"sensitive\", \"service\", \"share\", \"social\", \"south\", \"south\", \"stock\", \"stock\", \"store\", \"store\", \"subject\", \"support\", \"taiwan\", \"taiwan\", \"technology\", \"technology\", \"topic\", \"topic\", \"trump\", \"trump\", \"try\", \"two\", \"two\", \"upgrading\", \"use\", \"use\", \"value\", \"version\", \"version\", \"via\", \"video\", \"war\", \"week\", \"week\", \"whether\", \"whether\", \"word\", \"xi\", \"xi\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [1, 2]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el472350205229768055951742\", ldavis_el472350205229768055951742_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el472350205229768055951742\", ldavis_el472350205229768055951742_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el472350205229768055951742\", ldavis_el472350205229768055951742_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=              x    y  topics  cluster       Freq\n",
       "topic                                           \n",
       "0      0.068483  0.0       1        1  59.808721\n",
       "1     -0.068483  0.0       2        1  40.191279, topic_info=           Term       Freq      Total Category  logprob  loglift\n",
       "256     chatgpt   8.000000   8.000000  Default  30.0000  30.0000\n",
       "250         app  20.000000  20.000000  Default  29.0000  29.0000\n",
       "132       trump   8.000000   8.000000  Default  28.0000  28.0000\n",
       "290      monday   7.000000   7.000000  Default  27.0000  27.0000\n",
       "110       rival   5.000000   5.000000  Default  26.0000  26.0000\n",
       "..          ...        ...        ...      ...      ...      ...\n",
       "36          day   3.298725   4.789917   Topic2  -5.2280   0.5385\n",
       "83          new   3.641267   7.203024   Topic2  -5.1292   0.2294\n",
       "4           agi   3.846228  10.423995   Topic2  -5.0744  -0.0855\n",
       "300       store   3.348530   6.401129   Topic2  -5.2130   0.2636\n",
       "127  technology   3.579956  14.457441   Topic2  -5.1462  -0.4843\n",
       "\n",
       "[134 rows x 6 columns], token_table=      Topic      Freq     Term\n",
       "term                          \n",
       "4         1  0.671528      agi\n",
       "4         2  0.383730      agi\n",
       "148       1  0.777729     also\n",
       "148       2  0.155546     also\n",
       "149       1  0.829113   answer\n",
       "...     ...       ...      ...\n",
       "139       1  0.179143  whether\n",
       "139       2  0.716572  whether\n",
       "247       1  0.931137     word\n",
       "144       1  0.931951       xi\n",
       "144       2  0.155325       xi\n",
       "\n",
       "[150 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[1, 2])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim.prepare(lda_model, corpus, dictionary)\n",
    "vis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fbb1ca7a-d212-4413-82d4-6702e96371a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tomotopy as tp\n",
    "import little_mallet_wrapper\n",
    "import seaborn\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "01be8a8d-3fc9-43c9-b7b3-da017302444e",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"negative_DeepSeek_texts\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f725bb24-6544-4fb8-9088-ae59330a51e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob(f\"{directory}/*.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "db26a85d-4367-4bc8-a24f-38dc6242873d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Global_AI_rivalry_is_a_dangerous_game', \"What_questions_will_China's_DeepSeek_not_answer?_–\", \"DeepSeek:_Is_China's_AI_tool_as_good_as_it_seems?\", 'First_Thing:_Donald_Trump_calls_China’s_DeepSeek_A', 'South_Korea_Bans_Downloads_of_DeepSeek,_the_Chines', 'DeepSeek_has_ripped_away_AI’s_veil_of_mystique._Th', 'Diving_into_DeepSeek:_inside_the_7_February_Guardi']\n"
     ]
    }
   ],
   "source": [
    "training_data = []\n",
    "original_texts = []\n",
    "titles = []\n",
    "\n",
    "for file in files:\n",
    "    text = open(file, encoding='utf-8').read()\n",
    "    processed_text = little_mallet_wrapper.process_string(text, numbers='remove')\n",
    "    training_data.append(processed_text)\n",
    "    original_texts.append(text)\n",
    "    titles.append(Path(file).stem)\n",
    "print(titles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7e74d82f-8bfb-4ee6-8399-735a6aa7edbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 7, 7)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_data), len(original_texts), len(titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a43cc24e-b925-45a6-82e7-b4ec59afd1a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic Model Training...\n",
      "\n",
      "\n",
      "Iteration: 0\tLog-likelihood: -8.995984777730174\n",
      "Iteration: 10\tLog-likelihood: -8.960639241389044\n",
      "Iteration: 20\tLog-likelihood: -8.94466734824113\n",
      "Iteration: 30\tLog-likelihood: -8.940468452542062\n",
      "Iteration: 40\tLog-likelihood: -8.931678306548205\n",
      "Iteration: 50\tLog-likelihood: -8.910380112384805\n",
      "Iteration: 60\tLog-likelihood: -8.925085632143041\n",
      "Iteration: 70\tLog-likelihood: -8.882198243062712\n",
      "Iteration: 80\tLog-likelihood: -8.888182460949682\n",
      "Iteration: 90\tLog-likelihood: -8.887349981822982\n",
      "\n",
      "Topic Model Results:\n",
      "\n",
      "\n",
      "✨Topic 0✨\n",
      "\n",
      "china chinese version english political government human part responses new\n",
      "\n",
      "✨Topic 1✨\n",
      "\n",
      "taiwan however agi one said asked intelligence even word trump\n",
      "\n",
      "✨Topic 2✨\n",
      "\n",
      "deepseek technology chatbot questions response chatgpt app answers openai time\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Number of topics to return\n",
    "num_topics = 3\n",
    "# Numer of topic words to print out\n",
    "num_topic_words = 10\n",
    "# Intialize the model\n",
    "model = tp.LDAModel(k=num_topics)\n",
    "\n",
    "# Add each document to the model, after splitting it up into words\n",
    "for text in training_data:\n",
    "    model.add_doc(text.strip().split())\n",
    "    \n",
    "print(\"Topic Model Training...\\n\\n\")\n",
    "# Iterate over the data 10 times\n",
    "iterations = 10\n",
    "for i in range(0, 100, iterations):\n",
    "    model.train(iterations)\n",
    "    print(f'Iteration: {i}\\tLog-likelihood: {model.ll_per_word}')\n",
    "\n",
    "print(\"\\nTopic Model Results:\\n\\n\")\n",
    "# Print out top 10 words for each topic\n",
    "topics = []\n",
    "topic_individual_words = []\n",
    "for topic_number in range(0, num_topics):\n",
    "    topic_words = ' '.join(word for word, prob in model.get_topic_words(topic_id=topic_number, top_n=num_topic_words))\n",
    "    topics.append(topic_words)\n",
    "    topic_individual_words.append(topic_words.split())\n",
    "    print(f\"✨Topic {topic_number}✨\\n\\n{topic_words}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f948f66d-0172-46eb-b7d4-ed80214fb9f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (numpy_env)",
   "language": "python",
   "name": "numpy_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
