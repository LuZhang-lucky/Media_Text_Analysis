# Sentiment and Topic Analysis of News Coverage

This project analyzes sentiment trends and key discussion topics from international news coverage using Python and Jupyter Notebooks. It demonstrates the application of Natural Language Processing (NLP) techniques, exploratory data analysis, and data visualization in a real-world scenario.

## Project Background

This project began in Februaryâ€“March 2025 as part of the master's course **Distant Reading** in Digital Humanities. At that time, news about **DeepSeek** had just emerged, and we had a mini-project assignment for the course. I decided to analyze newsletters about DeepSeek out of curiosity, using the opportunity to explore media coverage of this trending topic.

The initial version of the project was completed under tight time constraints, so the first version was raw, with a small corpus and limited depth.

During the summer of 2025, I revisited the project with more time to study and apply methods from the learning material *Introduction to Cultural Analytics and Python*(Designed by Melanie Walsh)ï¼ˆhttps://melaniewalsh.github.io/Intro-Cultural-Analytics/welcome.htmlï¼‰. I expanded the corpus and reworked the analysis, producing this **2.0 version** with a more structured workflow, larger dataset, and improved insights.


## ğŸ“ Project Structure


```
DeepSeek_Media_Text_Analysis/
â”œâ”€â”€ 1_Datacollection/                # ğŸ“Š Collecting raw data & metadata
â”‚   â”œâ”€â”€ corpus_deepseek/             # Raw corpus with 100+ articles
â”‚   â”œâ”€â”€ all_texts.txt                # Combined text
â”‚   â”œâ”€â”€ corpus_set_up.jpynb          # Notebook
â”‚   â””â”€â”€ metadata_all_texts_complete.csv # Metadata
â”œâ”€â”€ 2_Preprocessing/                 # ğŸ§¹ Cleaning & preparing text data
â”‚   â”œâ”€â”€ corpus_deepseek_cleaned/     # Cleaned texts
â”‚   â”œâ”€â”€ nltk_preprocessing.ipynb
â”‚   â”œâ”€â”€ outputs/
â”‚   â”‚   â”œâ”€â”€ cleaned_text.txt
â”‚   â”‚   â””â”€â”€ word_frequency_all_texts.csv
â”‚   â””â”€â”€ visualizations/
â”‚       â””â”€â”€ wordcloud_output.png
â”œâ”€â”€ 3_TF-IDF/                        # ğŸ” Feature extraction with TF-IDF
â”‚   â”œâ”€â”€ heatmap_chart.html           # TF-IDF visualization
â”‚   â”œâ”€â”€ tfidf_all_corpus.jpynb       # Notebook
â”‚   â””â”€â”€ top_tfidf_results.csv        # Output
â”œâ”€â”€ 4_topic_modeling/                # ğŸ§  Topic modeling with LDA / Tomotopy
â”‚   â”œâ”€â”€ topic_gensim.ipynb
â”‚   â””â”€â”€ topic_tomotopy.ipynb
â”œâ”€â”€ 5_sentiment_analysis/            # ğŸ˜Š Sentiment & opinion mining
â”‚   â”œâ”€â”€ negative_DeepSeek_texts/     # Subcorpus: all negative texts
â”‚   â”œâ”€â”€ notebooks/
â”‚   â”‚   â”œâ”€â”€ sentiment_analysis_word.ipynb
â”‚   â”‚   â”œâ”€â”€ sentiment_transformers.ipynb
â”‚   â”‚   â”œâ”€â”€ vader_sentiment_deepseek.ipynb
â”‚   â”‚   â”œâ”€â”€ negative_texts_tfidf.ipynb
â”‚   â”‚   â”œâ”€â”€ POS_keywords_neg_texts.ipynb
â”‚   â”‚   â””â”€â”€ topic_negative_texts.ipynb
â”‚   â”œâ”€â”€ outputs/
â”‚   â”‚   â”œâ”€â”€ deepseek_vadersentiment_results.csv
â”‚   â”‚   â”œâ”€â”€ negative_sentiment_words_update.csv
â”‚   â”‚   â”œâ”€â”€ positive_sentiment_words_update_merge.csv
â”‚   â”‚   â”œâ”€â”€ sentiment_transformers_deepseek.csv
â”‚   â”‚   â”œâ”€â”€ sentiment_word_frequencies_textblob_update.csv
â”‚   â”‚   â”œâ”€â”€ tfidf_negative_texts.csv
â”‚   â”‚   â””â”€â”€ negative_texts.csv
â”‚   â””â”€â”€ visualizations/
â”‚       â”œâ”€â”€ sentiment_over_time.png
â”‚       â”œâ”€â”€ sentiment_over_time.html
â”‚       â”œâ”€â”€ negative_word_frequency_vs_sentiment.png
â”‚       â”œâ”€â”€ negative_word_frequency_vs_sentiment_zoom_in.png
â”‚       â”œâ”€â”€ positive_word_frequency_vs_sentiment.png
â”‚       â””â”€â”€ Negative_texts_TF-IDF_Score.html
â””â”€â”€ README.md                        # ğŸ“˜ Project documentation (v2.0)
```


## ğŸš€ Main Features

- Text preprocessing and cleaning with Python
- Sentiment analysis using lexicons and frequency calculations
- Topic modeling using LDA (Latent Dirichlet Allocation)
- Data visualization with Matplotlib
- Interactive exploratory analysis in Jupyter Notebooks

## ğŸ› ï¸ Tools and Libraries Used

- Python 3.x
- Jupyter Notebook
- Pandas
- NLTK
- Gensim
- Matplotlib

## ğŸ“Œ How to Use

1. Clone or download this repository to your local machine.
2. Install the required Python packages using:
   ```
   pip install -r requirements.txt
   ```
3. Open the notebooks with Jupyter:
   ```
   jupyter notebook
   ```
4. Navigate to the `notebooks/` folder and run the notebook step by step to reproduce the analysis.

## ğŸ’¡ Author

**Lu Zhang**  
Ph.D. in Social History, transitioning into Data Science with a focus on text analysis and data visualization. Currently pursuing a Master's in Digital Humanities at Uppsala University, Sweden.
